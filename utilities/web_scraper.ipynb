{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f888337",
   "metadata": {},
   "source": [
    "# Import Libraries and Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "daa1b0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The jupyternotify extension is already loaded. To reload it, use:\n",
      "  %reload_ext jupyternotify\n"
     ]
    }
   ],
   "source": [
    "%load_ext jupyternotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8462ca91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "from datetime import date, timedelta\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import urllib\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import threading\n",
    "from threading import Timer\n",
    "from time import sleep\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ec1ffc",
   "metadata": {},
   "source": [
    "# Read CSV and TXT Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a74fd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_teams = open(\"data/bad_teams.txt\", \"r\").read().strip().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1fbef8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matchups_df = pd.read_csv(\"data\\cbb_matchups.csv\")\n",
    "# matchups_dict = matchups_df.to_dict('records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f3149b",
   "metadata": {},
   "source": [
    "### Functions for URLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bee0f5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHTMLdocument(url):\n",
    "    \"\"\" \n",
    "    Sends GET request to the givin url and returns the html document \n",
    " \n",
    "    Args: \n",
    "        url - string: HTTP URL to send the GET request\n",
    "    Returns: \n",
    "        Response of GET request in HTML format\n",
    "     \n",
    "    \"\"\" \n",
    "    response = requests.get(url)\n",
    "\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a5a5e84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to test if a url returns a 404\n",
    "def testURL(url):\n",
    "    \"\"\" \n",
    "        Sends GET request to the givin url and returns the html document \n",
    " \n",
    "    Args: \n",
    "        url - string: HTTP URL to send the GET request\n",
    "    Returns: \n",
    "        Response code of GET request along with the url\n",
    "    \"\"\" \n",
    "    response_code = requests.get(url).status_code\n",
    "    response_string = f'URL: {url}\\nResponse: {response_code}\\n'\n",
    "    \n",
    "    return response_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3920656",
   "metadata": {},
   "source": [
    "# Create Matchups CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dbe94a",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0744b4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDates(start, end):\n",
    "    \"\"\" \n",
    "    Creates dates for a specified range \n",
    " \n",
    "    Args: \n",
    "        start - date: starting date\n",
    "        end - date: ending date \n",
    "    Returns: \n",
    "        date_list - list<datetime.date>: list of dates from start -> end \n",
    " \n",
    "    \"\"\"\n",
    "    date_list = []\n",
    "    delta = end - start \n",
    "\n",
    "    for i in range(delta.days + 1):\n",
    "        day = start + timedelta(days=i)\n",
    "        if day.month > 10 or day.month < 5: # Only need months 11 - 4 (November - April)\n",
    "            date_list.append(day)\n",
    "    \n",
    "    return date_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad9d4b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create urls to use to get matchups\n",
    "def createDatesURL(date_list):\n",
    "    \"\"\" \n",
    "    Formats and creates urls for the dates that are given\n",
    " \n",
    "    Args: \n",
    "        date_list - list<datetime.date>: list of dates \n",
    "    Returns: \n",
    "        date_url_list - list<str>: list of urls for the given dates \n",
    "        \n",
    "    \"\"\"\n",
    "    date_url_list = []\n",
    "\n",
    "    for date in date_list:\n",
    "        \n",
    "        # Format the dates into strings for the url\n",
    "        year = str(date.year)\n",
    "        month = str(date.month) if len(str(date.month)) == 2 else \"0\" + str(date.month)\n",
    "        day = str(date.day) if len(str(date.day)) == 2 else \"0\" + str(date.day)\n",
    "        season = f'{date.year}-{date.year + 1}' if len(str(date.month)) == 2 else f'{date.year - 1}-{date.year}'\n",
    "        \n",
    "        url = f'https://newsday.sportsdirectinc.com/sports-scores/College-Basketball-Scores-Matchups.aspx?Year={year}&Period={month}{day}&CurrentSeason={season}'\n",
    "        date_url_list.append({\"url\": url, \"date\": date})\n",
    "        \n",
    "    return date_url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba6ceff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to scrape webpage to get all matchups\n",
    "def getMatchups(date_url_list):\n",
    "    \"\"\" \n",
    "    Scrapes website to gather all games that were played in a given time frame\n",
    "    Will gather the teams, rankings, url for the box score, and date\n",
    " \n",
    "    Args: \n",
    "        date_url_list - list<dict>: dictionary containing all the urls along with the dates \n",
    "    Returns: \n",
    "        matchups_list - list<dict>: dictionary containing necessary matchup components \n",
    " \n",
    "    \"\"\"\n",
    "    matchups_list = []\n",
    "    \n",
    "    for date_url_index in range(len(date_url_list)):\n",
    "        \n",
    "        html_document = getHTMLdocument(date_url_list[date_url_index]['url'])\n",
    "        soup = BeautifulSoup(html_document, 'html.parser') # soup object\n",
    "        results = soup.find(id='Scoreboard_7_All_Games') # all of the necessary info is in this div \n",
    "\n",
    "        if results is not None: # dates that do not have games played on them will be None\n",
    "            \n",
    "            matchup_elements = results.find_all('div', class_='sdi-so-title') # each div in matchup elements is a matchup\n",
    "            \n",
    "            for matchup_index in range(len(matchup_elements)):\n",
    "            \n",
    "                matchup_text = matchup_elements[matchup_index].text.strip()\n",
    "                teams = re.split(r'( vs )|( at )', matchup_text) # ex. Purdue(1) at Michigan -> ['Purdue(1)', ' at ', 'Michigan']\n",
    "                teams = [i for i in teams if i is not None]\n",
    "                neutral = True if teams[1] == ' vs ' else False # ' vs ' indicates a neutral game \n",
    "\n",
    "                for team_index in range(0, len(teams), 2):\n",
    "                    team = re.split(r'\\((?=[\\d])|(?<=[\\d])\\)', teams[team_index]) # Extracts ranking from team ex. Purdue(1) -> ['Purdue', '1']\n",
    "                    team = [i for i in team if i != \"\"]\n",
    "\n",
    "                    if team_index == 0: # 0 index is away team\n",
    "                        away_team = team[0]\n",
    "                        away_team_ranking = int(team[1]) if len(team) == 2 else 0 # If team has no ranking, assign 0\n",
    "\n",
    "                    else: # other index is the home team\n",
    "                        home_team = team[0]\n",
    "                        home_team_ranking = int(team[1]) if len(team) == 2 else 0\n",
    "\n",
    "                find_href_results = results.find_all('div', class_='onoff') # div where box score url is\n",
    "                \n",
    "                # checks if url exists\n",
    "                links = find_href_results[matchup_index].find_all('a', href=True)\n",
    "                if(len(links) > 0):\n",
    "                    for i in range(len(links)):\n",
    "                        print(links[i].text)\n",
    "                        if links[i].text == 'boxscore': \n",
    "                            box_score_url = links[i]['href']\n",
    "                            print(links[i]['href'])\n",
    "                else:\n",
    "                    box_score_url = 'na'\n",
    "\n",
    "                matchups_list.append({\n",
    "                    'away_team': away_team,\n",
    "                    'away_team_ranking': away_team_ranking,\n",
    "                    'home_team': home_team,\n",
    "                    'home_team_ranking': home_team_ranking,\n",
    "                    'neutral': neutral,\n",
    "                    'box_score_url': box_score_url,\n",
    "                    'date': date_url_list[date_url_index]['date']\n",
    "                })\n",
    "                # {'away_team': 'Purdue', 'away_team_ranking': 1, 'home_team', 'home_team': 'Michigan', 'home_team_ranking': 0, 'neutral': False}\n",
    "\n",
    "    return matchups_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ee09b6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBox(box_div):\n",
    "    \"\"\" \n",
    "    Scrapes website to get box score of a team\n",
    "    This will gather all major statistics of every player on that team's roster\n",
    " \n",
    "    Args: \n",
    "        box_div - list<str>: list of the divs that contain the table which contains the statistics \n",
    "    Returns: \n",
    "        box - dict<dict>: dictionary of every player on the team; each player is represented by a dictionary of that player's stats \n",
    " \n",
    "    \"\"\"\n",
    "    box = {}\n",
    "    for row in range(2, len(box_div) - 2):        \n",
    "        stat_results = box_div[row].find_all(\"td\")\n",
    "        stats_dict = {}\n",
    "        if len(stat_results) == 14:\n",
    "            for stat in range(len(stat_results)):\n",
    "                if stat == 0:\n",
    "                    # checks if url exists\n",
    "                    if(len(stat_results[stat]('a', href=True)) > 0):\n",
    "                        player_url_id = stat_results[stat].find_all('a', href=True)[0]['href']\n",
    "                        player_url_id = re.split(r'r(?=[\\d])|(?<=[\\d])\\.', player_url_id)\n",
    "                        stats_dict['player_url_id'] = player_url_id[1]\n",
    "                    else:\n",
    "                        stats_dict['player_url_id'] = 'na'\n",
    "                    \n",
    "                elif stat == 1:\n",
    "                    stats_dict['min_played'] = int(stat_results[stat].text.strip().split(':')[0])\n",
    "\n",
    "                elif stat == 2:\n",
    "                    fg_data = stat_results[stat].text.strip().split('-')\n",
    "                    stats_dict['fg'] = int(fg_data[0])\n",
    "                    stats_dict['fg_a'] = int(fg_data[1])\n",
    "\n",
    "                elif stat == 3:\n",
    "                    three_data = stat_results[stat].text.strip().split('-')\n",
    "                    stats_dict['two_point'] = int(stats_dict['fg']) - int(three_data[0])\n",
    "                    stats_dict['two_point_a'] = int(stats_dict['fg_a']) - int(three_data[1])\n",
    "                    stats_dict['three_point'] = int(three_data[0])\n",
    "                    stats_dict['three_point_a'] = int(three_data[1])\n",
    "\n",
    "                elif stat == 4:\n",
    "                    ft_data = stat_results[stat].text.strip().split('-')\n",
    "                    stats_dict['ft_a'] = int(ft_data[1])\n",
    "                    stats_dict['ft'] = int(ft_data[0])\n",
    "\n",
    "                elif stat == 5:\n",
    "                    stats_dict['orb'] = int(stat_results[stat].text.strip())\n",
    "\n",
    "                elif stat == 6:\n",
    "                    stats_dict['drb'] = int(stat_results[stat].text.strip())    \n",
    "\n",
    "                elif stat == 7:\n",
    "                    stats_dict['tot_reb'] = int(stat_results[stat].text.strip())\n",
    "\n",
    "                elif stat == 8:\n",
    "                    stats_dict['a'] = int(stat_results[stat].text.strip())\n",
    "\n",
    "                elif stat == 9:\n",
    "                    stats_dict['pf'] = int(stat_results[stat].text.strip())\n",
    "\n",
    "                elif stat == 10:\n",
    "                    stats_dict['stl'] = int(stat_results[stat].text.strip())\n",
    "\n",
    "                elif stat == 11:\n",
    "                    stats_dict['to'] = int(stat_results[stat].text.strip())\n",
    "\n",
    "                elif stat == 12:\n",
    "                    stats_dict['blk'] = int(stat_results[stat].text.strip())\n",
    "\n",
    "                elif stat == 13:\n",
    "                    stats_dict['pts'] = int(stat_results[stat].text.strip())\n",
    "\n",
    "                box[stat_results[0].text.strip()] = stats_dict\n",
    "        else:\n",
    "            stats_dict['min_played'] = 'nan'\n",
    "    return box\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b64d33d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGame(url):\n",
    "    \"\"\" \n",
    "    Scrapes website to gather all available information about a game including location, score, player stats, etc.\n",
    " \n",
    "    Args: \n",
    "        url - str: url of the website that contains game information and box score \n",
    "    Returns: \n",
    "        game_results - dict<>: dictionary containing all information and stats of the game \n",
    " \n",
    "    \"\"\"\n",
    "    html_document = getHTMLdocument(url)\n",
    "    soup = BeautifulSoup(html_document, 'html.parser') # soup object\n",
    "    results = soup.find('div', id='sdi-rail-content') # all of the necessary info is in this div\n",
    "    \n",
    "    if results is not None:\n",
    "        when_where_div = results.find(\"div\", class_=\"sdi-quickhits\").text.strip() # this div contains all the information for time and place of game\n",
    "        when_where_list = re.split('When: |Where: |Officials: |Attendance: ', when_where_div)\n",
    "        when_where_list = [i for i in when_where_list if i != \"\"]\n",
    "\n",
    "        game_time = re.split('\\xa0|, ', when_where_list[0])[0] #Extracts the time of the game ex. '7:00 PM'\n",
    "\n",
    "        where_list = re.split(', ', when_where_list[1])\n",
    "\n",
    "        if len(where_list) == 3: # Most games are structured ['arena', 'city', 'state']\n",
    "            arena = where_list[0]\n",
    "            city = where_list[1]\n",
    "            state = where_list[2]\n",
    "\n",
    "        else: # Out of country games are strucured ['arena', 'city']\n",
    "            arena = where_list[0]\n",
    "            city = where_list[1]\n",
    "            state = None\n",
    "\n",
    "        if len(when_where_list) == 4: # some divs dont have attendance, ones that dont will not be len 4\n",
    "            if when_where_list[3].strip().isnumeric:\n",
    "                attendance = when_where_list[3].strip()\n",
    "            else:\n",
    "                attendance = None # some have blank attendance or non numeric\n",
    "        else:\n",
    "            attendance = None\n",
    "\n",
    "        # divs that contains the scores and boxscorse of the game for both teams\n",
    "        results_div = results.find_all(\"div\", class_=\"sdi-so\")     \n",
    "        score_div = results_div[0].find_all(class_='sdi-datacell')\n",
    "\n",
    "        # len of score_div depends on how many overtimes there were, that is what this is checking\n",
    "        if len(score_div) == 8:\n",
    "            away_1 = int(score_div[1].text)\n",
    "            away_2 = int(score_div[2].text)\n",
    "            away_ot = 0\n",
    "            away_ot2 = 0\n",
    "            away_ot3 = 0\n",
    "            away_tot = away_1 + away_2 + away_ot + away_ot2 + away_ot3\n",
    "\n",
    "            home_1 = int(score_div[5].text)\n",
    "            home_2 = int(score_div[6].text)\n",
    "            home_ot = 0\n",
    "            home_ot2 = 0\n",
    "            home_ot3 = 0\n",
    "            home_tot = home_1 + home_2 + home_ot + home_ot2 + home_ot3\n",
    "\n",
    "        elif len(score_div) == 10:\n",
    "            away_1 = int(score_div[1].text)\n",
    "            away_2 = int(score_div[2].text)\n",
    "            away_ot = int(score_div[3].text)\n",
    "            away_ot2 = 0\n",
    "            away_ot3 = 0\n",
    "            away_tot = away_1 + away_2 + away_ot + away_ot2 + away_ot3\n",
    "\n",
    "            home_1 = int(score_div[6].text)\n",
    "            home_2 = int(score_div[7].text)\n",
    "            home_ot = int(score_div[8].text)\n",
    "            home_ot2 = 0\n",
    "            home_ot3 = 0\n",
    "            home_tot = home_1 + home_2 + home_ot + home_ot2 + home_ot3\n",
    "\n",
    "        elif len(score_div) == 12:\n",
    "            away_1 = int(score_div[1].text)\n",
    "            away_2 = int(score_div[2].text)\n",
    "            away_ot = int(score_div[3].text)\n",
    "            away_ot2 = int(score_div[4].text)\n",
    "            away_ot3 = 0\n",
    "            away_tot = away_1 + away_2 + away_ot + away_ot2 + away_ot3\n",
    "\n",
    "            home_1 = int(score_div[7].text)\n",
    "            home_2 = int(score_div[8].text)\n",
    "            home_ot = int(score_div[9].text)\n",
    "            home_ot2 = int(score_div[10].text)\n",
    "            home_ot3 = 0\n",
    "            home_tot = home_1 + home_2 + home_ot + home_ot2 + home_ot3\n",
    "\n",
    "        elif len(score_div) == 14:\n",
    "            away_1 = int(score_div[1].text)\n",
    "            away_2 = int(score_div[2].text)\n",
    "            away_ot = int(score_div[3].text)\n",
    "            away_ot2 = int(score_div[4].text)\n",
    "            away_ot3 = int(score_div[5].text)\n",
    "            away_tot = away_1 + away_2 + away_ot + away_ot2 + away_ot3\n",
    "\n",
    "            home_1 = int(score_div[8].text)\n",
    "            home_2 = int(score_div[9].text)\n",
    "            home_ot = int(score_div[10].text)\n",
    "            home_ot2 = int(score_div[11].text)\n",
    "            home_ot3 = int(score_div[12].text)\n",
    "            home_tot = home_1 + home_2 + home_ot + home_ot2 + home_ot3\n",
    "\n",
    "\n",
    "        if len(results_div) == 3:\n",
    "            home_box = results_div[2].find_all(\"tr\")\n",
    "            away_box = results_div[1].find_all(\"tr\")\n",
    "\n",
    "            away = getBox(away_box)\n",
    "            home = getBox(home_box)\n",
    "        \n",
    "        else:\n",
    "            away = 'na'\n",
    "            home = 'na'\n",
    "\n",
    "        game_results = {\n",
    "            'game_time': game_time,\n",
    "            'arena': arena,\n",
    "            'city': city,\n",
    "            'state': state,\n",
    "            'attendance': attendance,\n",
    "            'away_1': away_1,\n",
    "            'away_2': away_2,\n",
    "            'away_ot': away_ot,\n",
    "            'away_ot2': away_ot2,\n",
    "            'away_ot3': away_ot3,\n",
    "            'away_tot': away_tot,\n",
    "            'home_1': home_1,\n",
    "            'home_2': home_2,\n",
    "            'home_ot': home_ot,\n",
    "            'home_ot2': home_ot2,\n",
    "            'home_ot3': home_ot3,\n",
    "            'home_tot': home_tot,\n",
    "            'away': away,\n",
    "            'home': home\n",
    "        }\n",
    "\n",
    "        return game_results\n",
    "    else:\n",
    "        return {\n",
    "            'game_time': 'na',\n",
    "            'arena': 'na',\n",
    "            'city': 'na',\n",
    "            'state': 'na',\n",
    "            'attendance': 'na',\n",
    "            'away_1': 'na',\n",
    "            'away_2': 'na',\n",
    "            'away_ot': 'na',\n",
    "            'away_ot2': 'na',\n",
    "            'away_ot3': 'na',\n",
    "            'away_tot': 'na',\n",
    "            'home_1': 'na',\n",
    "            'home_2': 'na',\n",
    "            'home_ot': 'na',\n",
    "            'home_ot2': 'na',\n",
    "            'home_ot3': 'na',\n",
    "            'home_tot': 'na',\n",
    "            'away': 'na',\n",
    "            'home': 'na'\n",
    "        }\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d9bf393e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createBoxScores(matchups, start, end):\n",
    "    \"\"\" \n",
    "    Scrapes website to gather all games that were played in a given time frame\n",
    "    Will gather the teams, rankings, url for the box score, and date\n",
    " \n",
    "    Args: \n",
    "        date_url_list - list<dict>: dictionary containing all the urls along with the dates \n",
    "    Returns: \n",
    "        matchups_list - list<dict>: dictionary containing necessary matchup components \n",
    " \n",
    "    \"\"\"\n",
    "    box_scores_list = []\n",
    "    \n",
    "    for i in range(start, end):\n",
    "        if matchups[i]['box_score_url'] != 'na':\n",
    "            print(str(i - start) + '/' + str(end - start) + ' - ' + matchups[i]['away_team'] + ' vs ' + matchups[i]['home_team'] + ': ' + matchups[i]['date'])\n",
    "            box_scores_list.append(getGame(\"https://newsday.sportsdirectinc.com\" + matchups[i]['box_score_url']))  \n",
    "    return box_scores_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bcc60a",
   "metadata": {},
   "source": [
    "### Create dataframe of matchups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4b23ff50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# date_list = createDates(date(2010, 11, 8), date(2023, 4, 3))\n",
    "# date_url_list = createDatesURL(date_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cd53f406",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# box_scores_list = createBoxScores(matchups_dict, 17398, 23389)\n",
    "# df = pd.DataFrame(box_scores_list)\n",
    "# df.to_csv('2013-2014.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6daeea",
   "metadata": {},
   "source": [
    "### Create dataframe of teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4b481898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# teams = pd.DataFrame(matchups_df['home_team'].unique(), columns=['team'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d56077e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # cleanup dataframe\n",
    "\n",
    "# teams['lookup'] = teams['team'].str.lower()\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\" \", \"-\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"(\", \"\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\")\", \"\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\".\", \"\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"'\", \"\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"&\", \"\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"-st\", \"-state\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"-stateate\", \"-state\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"maryland---e-shore\", \"maryland-eastern-shore\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"tenn-martin\", \"tennessee-martin\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"nc-state\", \"north-carolina-state\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"vcu\", \"virginia-commonwealth\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"american-u\", \"american\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"middle-tennessee-state\", \"middle-tennessee\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"liu-brooklyn\", \"long-island-university\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"miami-florida\", \"miami-fl\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"uc-santa-barbara\", \"california-santa-barbara\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"st-josephs\", \"saint-josephs\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"loyola-maryland\", \"loyola-md\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"vmi\", \"virginia-military-institute\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"siu---edwardsville\", \"southern-illinois-edwardsville\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"albany\", \"albany-ny\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"loyola-chicago\", \"loyola-il\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"unlv\", \"nevada-las-vegas\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"st-marys\", \"saint-marys-ca\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"texas-am-cc\", \"texas-am-corpus-christi\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"new-jersey-tech\", \"njit\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"wis-milwaukee\", \"milwaukee\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"uab\", \"alabama-birmingham\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"md-baltimore-cty\", \"maryland-baltimore-county\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"nc-greensboro\", \"north-carolina-greensboro\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"st-francis-pa\", \"saint-francis-pa\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"uc-riverside\", \"california-riverside\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"elon-university\", \"elon\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"bowling-green\", \"bowling-green-state\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"monmouth-nj\", \"monmouth\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"nc-wilmington\", \"north-carolina-wilmington\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"charleston\", \"college-of-charleston\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"indiana---purdue\", \"iupui\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"prairie-view-am\", \"prairie-view\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"nocarolina-at\", \"north-carolina-at\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"st-johns\", \"st-johns-ny\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"cal-state---bakersfield\", \"cal-state-bakersfield\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"uc-davis\", \"california-davis\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"cal-poly-slo\", \"cal-poly\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"uc-irvine\", \"california-irvine\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"boston-u\", \"boston-university\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"nc-asheville\", \"north-carolina-asheville\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"csu-northridge\", \"cal-state-northridge\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"mount-state-marys\", \"mount-st-marys\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"grambling-state\", \"grambling\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"se-missouri-state\", \"southeast-missouri-state\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"william--mary\", \"william-mary\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"iupu---ft-wayne\", \"ipfw\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"central-conn-state\", \"central-connecticut-state\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"st-peters\", \"saint-peters\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"college-of-charleston-southern\", \"charleston-southern\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"umkc\", \"missouri-kansas-city\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"southern-miss\", \"southern-mississippi\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"the-citadel\", \"citadel\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"texas-rio-grande-valley\", \"texas-pan-american\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"little-rock\", \"arkansas-little-rock\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"lu-lafayette\", \"louisiana-lafayette\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"st-francis-brooklyn\", \"st-francis-ny\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"ul-monroe\", \"louisiana-monroe\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"unc-wilmington\", \"north-carolina-wilmington\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"unorth-carolina-asheville\", \"north-carolina-asheville\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"unorth-carolina-greensboro\", \"north-carolina-greensboro\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"unorth-carolina-wilmington\", \"north-carolina-wilmington\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"csu-fullerton\", \"cal-state-fullerton\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"houston-christian\", \"houston-baptist\", regex=True)\n",
    "# teams['lookup'] = teams['lookup'].str.replace(\"queens-university-of-charlotte\", \"queens-nc\", regex=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
